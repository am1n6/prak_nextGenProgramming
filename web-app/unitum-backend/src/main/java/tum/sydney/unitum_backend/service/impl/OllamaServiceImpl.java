package tum.sydney.unitum_backend.service.impl;

import org.springframework.ai.chat.client.ChatClient;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import tum.sydney.unitum_backend.dto.ChatDto;
import tum.sydney.unitum_backend.dto.MessageDto;
import tum.sydney.unitum_backend.entity.Chat;
import tum.sydney.unitum_backend.entity.Message;
import tum.sydney.unitum_backend.mapper.ChatMapper;
import tum.sydney.unitum_backend.service.ChatService;
import tum.sydney.unitum_backend.service.MessageService;
import tum.sydney.unitum_backend.service.OllamaService;

import java.util.List;


//todo to be updated
/**
 * Implementation of the OllamaService interface.
 * This service is responsible for handling interactions with the Ollama model, including
 * processing user prompts and generating responses from the model.
 * It involves saving messages to the database, creating a prompt for the model, and
 * receiving and saving the model's response.
 */
@Service
public class OllamaServiceImpl implements OllamaService {

    private final MessageService messageService;
    private final ChatService chatService;
    private final ChatClient chatClient;

    /**
     * Constructor to initialize the OllamaServiceImpl with required dependencies.
     *
     * @param builder The ChatClient.Builder to build the chat client.
     * @param messageService The service to handle message-related operations.
     * @param chatService The service to handle chat-related operations.
     */
    @Autowired
    public OllamaServiceImpl(ChatClient.Builder builder, MessageService messageService, ChatService chatService) {
        this.messageService = messageService;
        this.chatService = chatService;
        this.chatClient = builder
                .build();
    }

    /**
     * Creates a prompt for the model by iterating over the messages in a chat.
     * It formats each message based on the sender type (User or AI).
     * It improves the Chat Feature, but due to limited computational power, we cant use it for inference
     *
     * @param messageDtos A list of message DTOs to create the prompt from.
     * @return A string representing the formatted prompt for the model.
     */
    private String createPrompt(List<MessageDto> messageDtos) {
        StringBuilder promptBuilder = new StringBuilder();
        for (MessageDto messageDto : messageDtos) {
            Message.Sender sender = messageDto.getSender();
            String message = messageDto.getContent();
            if (sender.equals(Message.Sender.AI)) {
                promptBuilder.append(message).append("</s>");
            } else if (sender.equals(Message.Sender.User)) {
                promptBuilder.append("<s>").append("[INST]").append(message).append("[/INST]");
            }
        }
        System.out.println(promptBuilder.toString()); // For debugging purposes
        return promptBuilder.toString();
    }

    /**
     * Saves a message (either from the user or AI) to the database.
     *
     * @param sender The sender of the message (either User or AI).
     * @param content The content of the message.
     * @param chat The chat the message belongs to.
     * @return A MessageDto object representing the saved message.
     */
    private MessageDto saveMessage(Message.Sender sender, String content, Chat chat) {
        MessageDto messageDto = new MessageDto();
        messageDto.setSender(sender);
        messageDto.setContent(content);
        messageDto.setChat(chat);
        return messageService.createMessage(chat.getId(), messageDto);
    }

    /**
     * Sends a prompt to the Ollama model and retrieves the response.
     *
     * @param message The message to send to the model.
     * @return The response content generated by the model.
     */
    private synchronized String chatWithModel(String message) {
        return chatClient.prompt()
                .user(message)
                .call()
                .content();
    }

    /**
     * Prompts the Ollama model with the user's input and retrieves the model's response.
     * This method also handles saving the user prompt and the model's response to the database.
     *
     * @param chatId The ID of the chat where the prompt and response should be stored.
     * @param userPrompt The prompt provided by the user to send to the model.
     * @return The response from the Ollama model.
     */
    @Override
    public String promptTheModel(Long chatId, String userPrompt) {
        // Retrieve the chat by ID
        ChatDto chatDto = chatService.getChatById(chatId);

        // Save the user prompt in the database
        MessageDto promptDto = saveMessage(Message.Sender.User, userPrompt, ChatMapper.mapToChat(chatDto));
        chatDto.getMessages().add(promptDto);

        // Create the model prompt
        String modelPrompt = "[INST]<<SYS>> Generate one unit test for the following function <</SYS>>" + userPrompt + "[/INST]";

        // Save the AI response placeholder in the database
        MessageDto responseDto = saveMessage(Message.Sender.AI, "", ChatMapper.mapToChat(chatDto));

        // Send the prompt to the Ollama model and get the response
        String response = chatWithModel(modelPrompt);

        // Update the AI response in the database
        responseDto.setContent(response);
        messageService.updateMessageContent(responseDto.getId(), responseDto);

        return response;
    }
}
